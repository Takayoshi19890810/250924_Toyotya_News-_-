import os
import json
import time
import requests
from bs4 import BeautifulSoup
import gspread
from oauth2client.service_account import ServiceAccountCredentials

# ========== Google Sheets æ¥ç¶š ==========
def get_gspread_client():
    """GitHub Secrets ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã€gspread ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’è¿”ã™"""
    credentials_json_str = os.environ.get("GCP_SERVICE_ACCOUNT_KEY")
    if not credentials_json_str:
        raise RuntimeError("ç’°å¢ƒå¤‰æ•° GCP_SERVICE_ACCOUNT_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    credentials_dict = json.loads(credentials_json_str)
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    credentials = ServiceAccountCredentials.from_json_keyfile_dict(credentials_dict, scope)
    gc = gspread.authorize(credentials)
    return gc


# ========== Yahooãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° ==========
def scrape_yahoo_news(keyword: str, limit: int = 50):
    """Yahooãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢çµæœã‹ã‚‰è¨˜äº‹ä¸€è¦§ã‚’å–å¾—ã™ã‚‹"""
    print(f"ğŸ” Yahooãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢é–‹å§‹: {keyword}")

    url = f"https://news.yahoo.co.jp/search?p={keyword}&ei=utf-8"
    headers = {"User-Agent": "Mozilla/5.0"}

    res = requests.get(url, headers=headers)
    if res.status_code != 200:
        print(f"âŒ ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: {res.status_code}")
        return []

    soup = BeautifulSoup(res.text, "html.parser")
    articles = []

    for a in soup.select("a.sc-fjdhpX"):
        title = a.get_text(strip=True)
        link = a.get("href")
        if not title or not link:
            continue

        articles.append([title, link])
        if len(articles) >= limit:
            break

    print(f"âœ… {len(articles)} ä»¶å–å¾—")
    return articles


# ========== ã‚·ãƒ¼ãƒˆã¸ã®æ›¸ãè¾¼ã¿ ==========
def write_to_sheet(sh, keyword: str, articles: list):
    """å–å¾—ã—ãŸè¨˜äº‹ãƒªã‚¹ãƒˆã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«æ›¸ãè¾¼ã‚€"""
    sheet_name = keyword
    try:
        worksheet = sh.worksheet(sheet_name)
    except gspread.exceptions.WorksheetNotFound:
        worksheet = sh.add_worksheet(title=sheet_name, rows="1000", cols="5")

    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
    worksheet.update("A1:B1", [["ã‚¿ã‚¤ãƒˆãƒ«", "URL"]])

    # è¨˜äº‹ãƒ‡ãƒ¼ã‚¿
    if articles:
        worksheet.update(f"A2:B{len(articles)+1}", articles)


# ========== ãƒ¡ã‚¤ãƒ³å‡¦ç† ==========
def main():
    keyword = os.environ.get("KEYWORD", "æ—¥ç”£")
    spreadsheet_id = os.environ.get("SPREADSHEET_ID")

    if not spreadsheet_id:
        raise RuntimeError("SPREADSHEET_ID ãŒæœªè¨­å®šã§ã™ã€‚")

    # gspread ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæº–å‚™
    gc = get_gspread_client()
    sh = gc.open_by_key(spreadsheet_id)

    # Yahooãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—
    articles = scrape_yahoo_news(keyword, limit=50)

    # æ›¸ãè¾¼ã¿
    write_to_sheet(sh, keyword, articles)
    print("âœ… å®Œäº†ã—ã¾ã—ãŸã€‚")


if __name__ == "__main__":
    main()
